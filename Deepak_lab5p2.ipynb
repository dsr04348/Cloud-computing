{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO1j/YDaVNlr8W43inv5DkU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5sX4KynPXrjS","executionInfo":{"status":"ok","timestamp":1699068505598,"user_tz":240,"elapsed":14580,"user":{"displayName":"Deepak Rajput","userId":"05967956653754579826"}},"outputId":"244812c0-a96c-4154-e359-fee255ffe1e9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive',force_remount=True)"]},{"cell_type":"code","source":["!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q https://archive.apache.org/dist/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz\n","!tar xf spark-3.2.0-bin-hadoop3.2.tgz\n","!pip install -q findspark"],"metadata":{"id":"GeUxj9gtYCV4","executionInfo":{"status":"ok","timestamp":1699068607814,"user_tz":240,"elapsed":37312,"user":{"displayName":"Deepak Rajput","userId":"05967956653754579826"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"spark-3.2.0-bin-hadoop3.2\""],"metadata":{"id":"JUNaJAscYY5D","executionInfo":{"status":"ok","timestamp":1699068616665,"user_tz":240,"elapsed":183,"user":{"displayName":"Deepak Rajput","userId":"05967956653754579826"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import findspark\n","findspark.init()"],"metadata":{"id":"jFcU0e42Yav5","executionInfo":{"status":"ok","timestamp":1699068630015,"user_tz":240,"elapsed":142,"user":{"displayName":"Deepak Rajput","userId":"05967956653754579826"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from numpy.random import uniform as u\n","import pyspark\n","from pyspark import SparkContext, SparkConf\n","from pyspark.sql.session import SparkSession\n","from pyspark.sql import *\n","from pyspark.sql.types import *\n","import re\n","sc = pyspark.SparkContext('local[*]')\n","\n","spark = pyspark.sql.session.SparkSession.builder.enableHiveSupport().getOrCreate()"],"metadata":{"id":"1tgA0XCCYeCp","executionInfo":{"status":"ok","timestamp":1699068655705,"user_tz":240,"elapsed":8629,"user":{"displayName":"Deepak Rajput","userId":"05967956653754579826"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["## This is a directed graph with 25 nodes (node 1 to node 25)\n","## Read and store the data as an adjacency list (use RDD or DataFrame).\n","## Use Spark/SparkSQL functionalities to answer the following questions.\n","###data insight\n","import pandas as pd\n","file = \"/content/gdrive/My Drive/graph data.csv\"\n","data = pd.read_csv(file, header=None)\n","graph_data = data.values.tolist()\n","print(graph_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lw_uWIMZYpqy","executionInfo":{"status":"ok","timestamp":1699068686255,"user_tz":240,"elapsed":813,"user":{"displayName":"Deepak Rajput","userId":"05967956653754579826"}},"outputId":"cb732d8e-9ff3-4377-a818-39326b37c5c0"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1], [1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0], [0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1], [0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0], [0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1], [1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0], [0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1], [0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0], [1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0], [1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1], [1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0], [0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0], [1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0], [0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0], [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1], [1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0], [0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0], [0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0], [0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1], [0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1], [1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0], [0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0], [0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0], [0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0]]\n"]}]},{"cell_type":"code","source":["##1. Read and store the data as an adjacency list (use RDD or DataFrame).\n","from pyspark.sql.functions import col, sum, when\n","adjacency_list = []\n","j = 0\n","for row in graph_data:\n","    j = j+1\n","    node_id = j\n","    connections = [i for i, value in enumerate(row[0:], 1) if value == 1]\n","    adjacency_list.append((node_id, connections))\n","\n","df1 = spark.createDataFrame(adjacency_list, [\"Node\", \"Connections\"])\n","df1.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VPe3SsboYro3","executionInfo":{"status":"ok","timestamp":1699068711496,"user_tz":240,"elapsed":9426,"user":{"displayName":"Deepak Rajput","userId":"05967956653754579826"}},"outputId":"0eac9573-4ef0-4e93-e2b7-21687ebe7313"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["+----+--------------------+\n","|Node|         Connections|\n","+----+--------------------+\n","|   1|[2, 4, 5, 7, 8, 9...|\n","|   2|[1, 4, 7, 9, 12, ...|\n","|   3|[2, 4, 5, 9, 14, ...|\n","|   4|[2, 3, 7, 11, 12,...|\n","|   5|[3, 4, 6, 7, 8, 1...|\n","|   6|[1, 3, 4, 7, 9, 1...|\n","|   7|[4, 6, 8, 9, 11, ...|\n","|   8|[2, 4, 10, 11, 12...|\n","|   9|[1, 4, 5, 8, 10, ...|\n","|  10|[1, 2, 4, 5, 9, 1...|\n","|  11|[1, 2, 4, 7, 9, 1...|\n","|  12|[3, 4, 5, 7, 10, ...|\n","|  13|[1, 2, 4, 10, 11,...|\n","|  14|[2, 5, 6, 8, 9, 1...|\n","|  15|[2, 3, 4, 5, 11, ...|\n","|  16|[1, 2, 7, 9, 11, ...|\n","|  17|[2, 4, 8, 9, 14, ...|\n","|  18|[3, 4, 9, 11, 12,...|\n","|  19|[2, 11, 14, 16, 1...|\n","|  20|[2, 3, 7, 10, 15,...|\n","+----+--------------------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"code","source":["adjacency_rdd = spark.sparkContext.parallelize(adjacency_list)\n","adjacency_rdd.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Er21TB_4YzJU","executionInfo":{"status":"ok","timestamp":1699068723257,"user_tz":240,"elapsed":306,"user":{"displayName":"Deepak Rajput","userId":"05967956653754579826"}},"outputId":"ca2e447a-cc4f-431f-d3cb-4abd4b73d7de"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(1, [2, 4, 5, 7, 8, 9, 12, 14, 15, 17, 18, 20, 22, 24, 25]),\n"," (2, [1, 4, 7, 9, 12, 15, 17, 19, 22, 24]),\n"," (3, [2, 4, 5, 9, 14, 15, 18, 22, 23, 25]),\n"," (4, [2, 3, 7, 11, 12, 14, 17, 18, 21, 23, 24]),\n"," (5, [3, 4, 6, 7, 8, 12, 14, 17, 18, 19, 24, 25]),\n"," (6, [1, 3, 4, 7, 9, 11, 12, 14, 17, 18, 21, 22, 23]),\n"," (7, [4, 6, 8, 9, 11, 12, 15, 18, 19, 21, 22, 25]),\n"," (8, [2, 4, 10, 11, 12, 13, 14, 15, 19, 22, 23, 24]),\n"," (9, [1, 4, 5, 8, 10, 11, 14, 16, 20, 22, 23]),\n"," (10, [1, 2, 4, 5, 9, 11, 13, 16, 17, 19, 22, 24, 25]),\n"," (11, [1, 2, 4, 7, 9, 12, 17, 18, 19, 22, 23, 24]),\n"," (12, [3, 4, 5, 7, 10, 11, 14, 15, 21, 22, 23]),\n"," (13, [1, 2, 4, 10, 11, 12, 14, 16, 17, 19, 24]),\n"," (14, [2, 5, 6, 8, 9, 13, 18, 19, 21, 22, 24]),\n"," (15, [2, 3, 4, 5, 11, 16, 18, 20, 21, 23, 25]),\n"," (16, [1, 2, 7, 9, 11, 12, 13, 19, 21, 22, 24]),\n"," (17, [2, 4, 8, 9, 14, 15, 16, 22, 24]),\n"," (18, [3, 4, 9, 11, 12, 14, 16, 17, 22, 25]),\n"," (19, [2, 11, 14, 16, 17, 22, 24]),\n"," (20, [2, 3, 7, 10, 15, 16, 17, 19, 22, 25]),\n"," (21, [3, 4, 6, 7, 9, 13, 15, 16, 19, 20, 23, 24, 25]),\n"," (22, [1, 2, 4, 7, 12, 14, 15, 16, 19, 23, 24]),\n"," (23, [3, 4, 9, 11, 12, 14, 17, 18, 22, 24]),\n"," (24, [4, 8, 9, 10, 13, 16, 17, 21, 23]),\n"," (25, [3, 4, 5, 9, 11, 12, 14, 15, 20, 21, 22, 24])]"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# 1.  Find all self-loops (i.e. edge between a node onto itself)\n","self_loops = adjacency_rdd.filter(lambda x: x[0] in x[1])\n","self_loops.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w-23C5sFY0w7","executionInfo":{"status":"ok","timestamp":1699068735380,"user_tz":240,"elapsed":742,"user":{"displayName":"Deepak Rajput","userId":"05967956653754579826"}},"outputId":"ea78e2a0-25e6-4d3d-9a69-c8011a5200f6"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["# 2. Node with the largest out-degree\n","\n","largest_out_degree = adjacency_rdd.map(lambda x: (x[0], len(x[1]))).reduce(lambda x, y: x if x[1] > y[1] else y)\n","print(\"largest out-degree node:\", largest_out_degree[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P7UcqQCdY3w9","executionInfo":{"status":"ok","timestamp":1699068750678,"user_tz":240,"elapsed":663,"user":{"displayName":"Deepak Rajput","userId":"05967956653754579826"}},"outputId":"5f9d3512-90b9-4344-b015-64d5f701b805"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["largest out-degree node: 1\n"]}]},{"cell_type":"code","source":["# 3. Node with the larges in-degree\n","in_degree_rdd = adjacency_rdd.flatMap(lambda x: [(neighbor, 1) for neighbor in x[1]])\n","largest_in_degree = in_degree_rdd.reduceByKey(lambda x, y: x + y).reduce(lambda x, y: x if x[1] > y[1] else y)\n","print(\"largest in-degree node:\", largest_in_degree[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cb9ZlYBuY7Uv","executionInfo":{"status":"ok","timestamp":1699068763132,"user_tz":240,"elapsed":1395,"user":{"displayName":"Deepak Rajput","userId":"05967956653754579826"}},"outputId":"124f778f-ba00-4eaa-bc57-5a3f191f56dc"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["largest in-degree node: 4\n"]}]},{"cell_type":"code","source":["# 4. Find the distribution of vertices in-degrees\n","in_degrees = in_degree_rdd.countByKey()\n","print(\"the distribution of vertices in-degrees:\", in_degrees)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W8gyfurzZEMI","executionInfo":{"status":"ok","timestamp":1699068794496,"user_tz":240,"elapsed":1030,"user":{"displayName":"Deepak Rajput","userId":"05967956653754579826"}},"outputId":"53cd1698-3b4c-436a-e23e-ae758e1d8f85"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["the distribution of vertices in-degrees: defaultdict(<class 'int'>, {2: 14, 4: 20, 5: 8, 7: 11, 8: 7, 9: 15, 12: 14, 14: 15, 15: 11, 17: 13, 18: 10, 20: 5, 22: 18, 24: 16, 25: 9, 1: 8, 19: 12, 23: 11, 3: 10, 11: 14, 21: 9, 6: 4, 10: 6, 13: 6, 16: 11})\n"]}]},{"cell_type":"code","source":["# 5. Find a path between node 1 to node 9 [output: a list of nodes that connects 1 and 9]\n","def find_path(node, target, visited, path):\n","    visited[node] = True\n","    path.append(node)\n","\n","    if node == target:\n","        return path\n","\n","    neighbors = adjacency_rdd.filter(lambda x: x[0] == node).first()[1]\n","    for neighbor in neighbors:\n","        if not visited[neighbor]:\n","            result = find_path(neighbor, target, visited, path)\n","            if result:\n","                return result\n","\n","    path.pop()\n","    return None\n","\n","visited_nodes = [False] * 25\n","path_result = find_path(1, 9, visited_nodes, [])\n","print(\"path between node 1 to node 9:\", path_result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pOBVPAAFZGL3","executionInfo":{"status":"ok","timestamp":1699068814750,"user_tz":240,"elapsed":1415,"user":{"displayName":"Deepak Rajput","userId":"05967956653754579826"}},"outputId":"fdbd9b2f-0b0e-4a1e-e68e-fce3ee8f9f0f"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["path between node 1 to node 9: [1, 2, 4, 3, 5, 6, 7, 8, 10, 9]\n"]}]}]}